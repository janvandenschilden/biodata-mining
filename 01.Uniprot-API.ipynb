{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 01. Uniprot API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The [UniProt](https://www.uniprot.org/) knowledgebase is a large resource of protein sequences and associated detailed annotation.\n",
    "The moment this tutorial was written it contained close to 200 million sequences,\n",
    "of which more than half a million were curated by experts that critically review experimental and predicted data for each protein. [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## How to search this database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Uniprot provides a text search in which you describe the kind of data you are looking form in the form of queries. An image of how this search bar looks is given below.\n",
    "\n",
    "![](img/uniprot-search-bar.png)\n",
    "\n",
    "If this search bar is entered empty, uniprot will give back a list of all available sequences in the database. With advanced dropdown menu, it is possible to select specific fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Example 1.1: Search on website for all human proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Use the advanced dropdown menu and select the field \"Organism\" put in the value human and use the autocompletion to get what is shown below.\n",
    "\n",
    "![](img/uniprot-advanced-search.png)\n",
    "\n",
    "This gives the following value in the search bar,\n",
    "\n",
    "![](img/uniprot-search-human.png)\n",
    "\n",
    "and the following results.\n",
    "\n",
    "![](img/uniprot-search-human-results.png)\n",
    "\n",
    "We can use extra fields to further refine this search. \n",
    "For example, lets say we are only interested in those proteins that have a 3D structure available and are longer then 1000 amino acids.\n",
    "\n",
    "![](img/uniprot-search-human-big-structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Exercise 1.1: Search on website for all E. coli (strain K12) proteins with a signal peptide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "(Click dots for solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "annotation:(type:signal) AND organism:\"Escherichia coli (strain K12) [83333]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Exercise 1.2: Search on website for the protein with id P0AFL3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "(Click dots for solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```\n",
    "id:P0AFL3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Use Uniprot API to download files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "When you perform a query on the Uniprot website,\n",
    "you can download the results in different formats from the web page with the following button.\n",
    "\n",
    "![](img/uniprot-download.png)\n",
    "\n",
    "Simple right? Why would we need to automate this simple task with python.\n",
    "The thing is that if you want to download many different files, \n",
    "the task of filling in the query on the website and clicking the download button gets very repetitious.\n",
    "Lets say you want to download a list of protein identifiers for every protein that contains a signal peptide,\n",
    "and you want to that for 250 different organisms.\n",
    "Can you imagine yourself refilling the text search 250 times, \n",
    "pushing the download button 250 times,\n",
    "selecting the list format 250 times,\n",
    "choosing the destination on your computer 250 times ...\n",
    "You get the idea.\n",
    "It even gets worse, \n",
    "if after one week, you realize that having a signal peptide was not enough the research you are doing and the proteins also needs to have a length of at least 200 amino acids,\n",
    "you will have to redo all those steps again for 250 times.\n",
    "A python script could solve this problem in less then 10 lines of code.\n",
    "Additionally, you have your data collection method written down, \n",
    "which you could pass to other researchers if they want to recreate your dataset.\n",
    "\n",
    "So how does it work?\n",
    "Simple, uniprot requires a specific format of URL to know which data you want and then you can download this data.\n",
    "More information about the ins and outs can be found on this [link](https://www.uniprot.org/help/api%5Fqueries). \n",
    "Below I have written some functions that will generate a URL based on given parameters and download the requested file in the current working directory.\n",
    "If you are interested you can a look at them how they work, but this is not necessary.\n",
    "You can also just run the cell and skip towards the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def downloadFile(url,fileName):\n",
    "    \"\"\"\n",
    "    Downloads a file from the internet with a given url.\n",
    "    The function delete any existing files with the given filename.\n",
    "    It will then download and name the new file.\n",
    "    The function is designed to also work with very big files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        url that is needed used to download a file.\n",
    "    fileName : str\n",
    "        Name of the new file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fileName : str\n",
    "        returns the name of the new file\n",
    "    \"\"\"\n",
    "    # Delete existing files with filename\n",
    "    try:\n",
    "        os.remove(fileName) \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \"\"\" Use requests to download file. \n",
    "    Works with streams to be able large files without having the need of a \n",
    "    large memory.\n",
    "    \"\"\"\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(fileName, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    return fileName\n",
    "\n",
    "def uniprotDownload(fileName, query=\"\",format=\"list\",columns=\"\",include=\"no\",compress=\"no\",limit=0,offset=0):\n",
    "    \"\"\"Downloads file from uniprot for given parameters\n",
    "    \n",
    "    If no parameters are given the function will download a list of all the \n",
    "    proteins ID's. More information about how the URL should be constructed can\n",
    "    be found on: \n",
    "    https://www.uniprot.org/help/api%5Fqueries\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fileName : str\n",
    "        name for the downloaded file\n",
    "    query : str (Default='')\n",
    "        query that would be searched if as you used the webinterface on \n",
    "        https://www.uniprot.org/. If no query is provided, all protein entries\n",
    "        are selected. \n",
    "    format : str (Default='list')\n",
    "        File format you want to retrieve from uniprot. Available format are:\n",
    "        html | tab | xls | fasta | gff | txt | xml | rdf | list | rss\n",
    "    columns : str (Default='')\n",
    "        Column information you want to know for each entry in the query \n",
    "        when format tab or xls is selected.\n",
    "    include : str (Default='no')\n",
    "        Include isoform sequences when the format parameter is set to fasta.\n",
    "        Include description of referenced data when the format parameter is set to rdf.\n",
    "        This parameter is ignored for all other values of the format parameter.\n",
    "    compress : str (Default='no')\n",
    "        download file in gzipped compression format.\n",
    "    limit : int (Default=0)\n",
    "        Limit the amount of results that is given. 0 means you download all.\n",
    "    offset : int (Default=0)\n",
    "        When you limit the amount of results, offset determines where to start.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fileName : str\n",
    "        Name of the downloaeded file.\n",
    "    \"\"\"\n",
    "    def generateURL(baseURL, query=\"\",format=\"list\",columns=\"\",include=\"no\",compress=\"no\",limit=\"0\",offset=\"0\"):\n",
    "        \"\"\"Generate URL with given parameters\"\"\"\n",
    "        def glueParameters(**kwargs):\n",
    "            gluedParameters = \"\"\n",
    "            for parameter, value in kwargs.items():\n",
    "                gluedParameters+=parameter + \"=\" + str(value) + \"&\"\n",
    "            return gluedParameters.replace(\" \",\"+\")[:-1] #Last \"&\" is removed, spacec replaced by \"+\"\n",
    "        return baseURL + glueParameters(query=query,\n",
    "                                        format=format,\n",
    "                                        columns=columns,\n",
    "                                        include=include,\n",
    "                                        compress=compress,\n",
    "                                        limit=limit,\n",
    "                                        offset=offset)\n",
    "    URL = generateURL(\"https://www.uniprot.org/uniprot/?\",\n",
    "               query=query,\n",
    "               format=format,\n",
    "               columns=columns,\n",
    "               include=include,\n",
    "               compress=compress,\n",
    "               limit=limit,\n",
    "               offset=offset)\n",
    "    return downloadFile(URL, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### example 1.2 download in list format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In this example we will download a list file for all human proteins with protein length of at least 4000 amino acids.\n",
    "The list format is just a plain text file of all the protein identifiers that agree with the search query.\n",
    "Each protein identifier is unique, \n",
    "thus they can always be mapped back to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'humanProteins.list'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query as you give it in the textsearch\n",
    "QUERY='length:[4000 TO *] AND organism:\"Homo sapiens (Human) [9606]\"' \n",
    "FORMAT = 'list'                               \n",
    "filename = 'humanProteins.list'\n",
    "\n",
    "uniprotDownload(filename,format=FORMAT, query=QUERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# References\n",
    "\n",
    "[1]: UniProt: the universal protein knowledgebase. Nucleic acids research, 2017, 45.D1: D158-D169."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
